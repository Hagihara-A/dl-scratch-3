{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd09ae9af956ead1566f13a1f7974c005b386e9ee9f0e9e96b348213ed195e69c6d",
   "display_name": "Python 3.9.5  ('.venv': pipenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "9ae9af956ead1566f13a1f7974c005b386e9ee9f0e9e96b348213ed195e69c6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch: 1\n",
      "train_loss: 1.078, accuracy: 0.3733\n",
      "test_loss: 1.059, accuracy: 0.3867\n",
      "epoch: 21\n",
      "train_loss: 0.7921, accuracy: 0.54\n",
      "test_loss: 0.7963, accuracy: 0.53\n",
      "epoch: 41\n",
      "train_loss: 0.7461, accuracy: 0.5367\n",
      "test_loss: 0.753, accuracy: 0.5167\n",
      "epoch: 61\n",
      "train_loss: 0.7295, accuracy: 0.5533\n",
      "test_loss: 0.7431, accuracy: 0.5233\n",
      "epoch: 81\n",
      "train_loss: 0.7238, accuracy: 0.5567\n",
      "test_loss: 0.7332, accuracy: 0.5467\n",
      "epoch: 101\n",
      "train_loss: 0.7146, accuracy: 0.5567\n",
      "test_loss: 0.7286, accuracy: 0.57\n",
      "epoch: 121\n",
      "train_loss: 0.7066, accuracy: 0.56\n",
      "test_loss: 0.7155, accuracy: 0.56\n",
      "epoch: 141\n",
      "train_loss: 0.6937, accuracy: 0.58\n",
      "test_loss: 0.7057, accuracy: 0.57\n",
      "epoch: 161\n",
      "train_loss: 0.6773, accuracy: 0.6067\n",
      "test_loss: 0.6932, accuracy: 0.5667\n",
      "epoch: 181\n",
      "train_loss: 0.6602, accuracy: 0.6\n",
      "test_loss: 0.6755, accuracy: 0.6233\n",
      "epoch: 201\n",
      "train_loss: 0.6271, accuracy: 0.63\n",
      "test_loss: 0.6409, accuracy: 0.63\n",
      "epoch: 221\n",
      "train_loss: 0.5858, accuracy: 0.6633\n",
      "test_loss: 0.6015, accuracy: 0.6967\n",
      "epoch: 241\n",
      "train_loss: 0.5391, accuracy: 0.71\n",
      "test_loss: 0.5551, accuracy: 0.7267\n",
      "epoch: 261\n",
      "train_loss: 0.4903, accuracy: 0.76\n",
      "test_loss: 0.5078, accuracy: 0.75\n",
      "epoch: 281\n",
      "train_loss: 0.4456, accuracy: 0.78\n",
      "test_loss: 0.4621, accuracy: 0.78\n",
      "epoch: 301\n",
      "train_loss: 0.399, accuracy: 0.8333\n",
      "test_loss: 0.4206, accuracy: 0.8267\n",
      "epoch: 321\n",
      "train_loss: 0.3613, accuracy: 0.8533\n",
      "test_loss: 0.3822, accuracy: 0.8333\n",
      "epoch: 341\n",
      "train_loss: 0.327, accuracy: 0.8967\n",
      "test_loss: 0.3482, accuracy: 0.87\n",
      "epoch: 361\n",
      "train_loss: 0.2976, accuracy: 0.9067\n",
      "test_loss: 0.3198, accuracy: 0.8733\n",
      "epoch: 381\n",
      "train_loss: 0.2723, accuracy: 0.92\n",
      "test_loss: 0.2951, accuracy: 0.8867\n",
      "epoch: 401\n",
      "train_loss: 0.256, accuracy: 0.9167\n",
      "test_loss: 0.2753, accuracy: 0.8933\n",
      "epoch: 421\n",
      "train_loss: 0.236, accuracy: 0.93\n",
      "test_loss: 0.2584, accuracy: 0.8967\n",
      "epoch: 441\n",
      "train_loss: 0.2218, accuracy: 0.9367\n",
      "test_loss: 0.2431, accuracy: 0.91\n",
      "epoch: 461\n",
      "train_loss: 0.2085, accuracy: 0.9267\n",
      "test_loss: 0.2311, accuracy: 0.91\n",
      "epoch: 481\n",
      "train_loss: 0.1985, accuracy: 0.9333\n",
      "test_loss: 0.2215, accuracy: 0.92\n",
      "epoch: 501\n",
      "train_loss: 0.1889, accuracy: 0.94\n",
      "test_loss: 0.2117, accuracy: 0.9267\n",
      "epoch: 521\n",
      "train_loss: 0.1809, accuracy: 0.9467\n",
      "test_loss: 0.2058, accuracy: 0.9167\n",
      "epoch: 541\n",
      "train_loss: 0.1739, accuracy: 0.9533\n",
      "test_loss: 0.1979, accuracy: 0.93\n",
      "epoch: 561\n",
      "train_loss: 0.167, accuracy: 0.9467\n",
      "test_loss: 0.1927, accuracy: 0.9367\n",
      "epoch: 581\n",
      "train_loss: 0.1615, accuracy: 0.95\n",
      "test_loss: 0.1881, accuracy: 0.9367\n"
     ]
    }
   ],
   "source": [
    "from dezero.datasets import Spiral\n",
    "from dezero import DataLoader\n",
    "import numpy as np\n",
    "from dezero.models import MLP\n",
    "from dezero.optimizers import SGD as opt\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "batch_size = 30\n",
    "max_epoch = 600\n",
    "hidden_size = 10\n",
    "lr = 0.3\n",
    "\n",
    "train_set = Spiral(train=True)\n",
    "test_set = Spiral(train=False)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = opt(lr).setup(model)\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        acc = F.accuracy(y.data, t)\n",
    "        model.clear_grads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "        sum_acc += acc * len(t)\n",
    "    if (epoch%20==0):\n",
    "        print(f'epoch: {epoch+1}')\n",
    "        print(f'train_loss: {sum_loss/len(train_set):.4}, accuracy: {sum_acc/ len(train_set):.4}')\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    with dezero.config.no_grad():\n",
    "        for x, t in test_loader:\n",
    "            y = model(x)\n",
    "            loss = F.softmax_cross_entropy(y, t)\n",
    "            acc = F.accuracy(y.data, t)\n",
    "            sum_loss += float(loss.data) * len(t)\n",
    "            sum_acc += acc * len(t)\n",
    "        if (epoch%20==0):\n",
    "            print(f'test_loss: {sum_loss/len(test_set):.4}, accuracy: {sum_acc/ len(test_set):.4}')\n",
    "\n",
    "\n"
   ]
  }
 ]
}